version: '3.9'

services:
  agent-llama-70b:
    image: ghcr.io/huggingface/text-generation-inference:sha-4cce843
    environment:
      - CUDA_VISIBLE_DEVICES=0,1,2,3
      - MAX_INPUT_LENGTH=4096
      - MAX_TOTAL_TOKENS=16384
      - DTYPE=bfloat16
      - NUM_SHARD=4
    volumes:
      - ./tgi_data:/data
    ports:
      - "30070:80"
    command:
      - "--model-id"
      - "THUDM/agentlm-70b"
    deploy:
      resources:
        reservations:
          memory: 8g
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
